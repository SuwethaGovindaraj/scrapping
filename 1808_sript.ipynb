{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table.xlsx\", header=None)\n",
    "\n",
    "# Skip the first two rows and extract the remaining data\n",
    "df_table_remaining = df_table.iloc[2:]\n",
    "\n",
    "# Function to process each row, handling the required merging logic\n",
    "def process_row(row):\n",
    "    # Find the last occurrence of a cell with a dollar sign ($)\n",
    "    dollar_idx = None\n",
    "    for idx, cell in reversed(list(enumerate(row))):\n",
    "        if isinstance(cell, str) and '$' in cell:\n",
    "            dollar_idx = idx\n",
    "            break\n",
    "    \n",
    "    if dollar_idx is None:\n",
    "        # No dollar sign found, return the row as is\n",
    "        return row\n",
    "    \n",
    "    # Combine all cells after the last $ until the last two cells\n",
    "    combined_cell = \"_\".join(row[dollar_idx + 1:-2])\n",
    "    \n",
    "    # Keep the last two cells as separate columns\n",
    "    last_two_cells = row[-2:]\n",
    "    \n",
    "    # Construct the new row\n",
    "    new_row = list(row[:dollar_idx + 1]) + [combined_cell] + last_two_cells\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "# Apply the processing to each row\n",
    "processed_data = [process_row(row) for row in df_table_remaining.values]\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "df_cleaned = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_cleaned.to_excel(\"cleaned_extracted_table_remaining_corrected.xlsx\", index=False, header=False)\n",
    "\n",
    "print(\"Data extraction and splitting complete. Saved to cleaned_extracted_table_remaining_corrected.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "######working\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = 'img1.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(f\"Error: Unable to load image at path {image_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sharpen the image\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    sharp = cv2.filter2D(gray, -1, kernel)\n",
    "    \n",
    "    # Denoise the image\n",
    "    denoised = cv2.fastNlMeansDenoising(sharp, h=30)\n",
    "    \n",
    "    # Resize the image\n",
    "    height, width = denoised.shape\n",
    "    resized = cv2.resize(denoised, (width * 3, height * 3))\n",
    "    \n",
    "    # Apply both adaptive and global thresholding\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(resized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY, 11, 2)\n",
    "    _, global_thresh = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Combine both thresholding results\n",
    "    combined_thresh = cv2.bitwise_or(adaptive_thresh, global_thresh)\n",
    "    \n",
    "    return combined_thresh\n",
    "\n",
    "# Preprocess the image\n",
    "thresh = preprocess_image(image)\n",
    "\n",
    "# Use Tesseract to perform OCR with custom configurations\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT, config=custom_config)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Initialize variables to store row data\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = table_data['line_num'].min()\n",
    "\n",
    "# Iterate through the table data\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        if current_row:\n",
    "            rows.append(' '.join(current_row))\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    # Concatenate text within the same line\n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(' '.join(current_row))\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_table = pd.DataFrame(rows)\n",
    "\n",
    "# Ensure DataFrame has columns and rename them if needed\n",
    "# Assuming the first row of `rows` is the header\n",
    "if not df_table.empty:\n",
    "    header = df_table.iloc[0]\n",
    "    df_table = df_table[1:]\n",
    "    df_table.columns = header\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"extracted_table.xlsx\", index=False)\n",
    "\n",
    "print(\"Data extraction complete. Saved to extracted_table.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O split and _ \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table.xlsx\", header=None)\n",
    "\n",
    "# Skip the first two rows and extract the remaining data\n",
    "df_table_remaining = df_table.iloc[2:]\n",
    "\n",
    "# Convert the DataFrame to a single string to process all rows together\n",
    "all_text = ' '.join(df_table_remaining[0].dropna().astype(str).tolist())\n",
    "\n",
    "# Split the text by \"O \" followed by a space, but keep the delimiter in the result\n",
    "rows = re.split(r'(O )', all_text)\n",
    "rows = [''.join(pair) for pair in zip(rows[1::2], rows[2::2])]\n",
    "\n",
    "# Function to process each row, handling the required merging logic\n",
    "def process_row(row):\n",
    "    # Split the row into individual cells\n",
    "    pattern = re.compile(r'\".+?\"|[^\"\\s]+')\n",
    "    matches = pattern.findall(row)\n",
    "\n",
    "    # Strip quotes from the matched sentences\n",
    "    cleaned_matches = [match.strip('\"') for match in matches]\n",
    "\n",
    "    # Find the index of the last cell containing a dollar sign\n",
    "    dollar_idx = None\n",
    "    for idx, cell in reversed(list(enumerate(cleaned_matches))):\n",
    "        if '$' in cell:\n",
    "            dollar_idx = idx\n",
    "            break\n",
    "\n",
    "    if dollar_idx is None:\n",
    "        # No dollar sign found, return the cleaned row as is\n",
    "        return cleaned_matches\n",
    "    \n",
    "    # Combine all cells after the last $ until the last two cells\n",
    "    combined_cell = \"_\".join(cleaned_matches[dollar_idx + 1:-2])\n",
    "    \n",
    "    # Keep the last two cells as separate columns\n",
    "    last_two_cells = cleaned_matches[-2:]\n",
    "    \n",
    "    # Construct the new row\n",
    "    new_row = cleaned_matches[:dollar_idx + 1] + [combined_cell] + last_two_cells\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "# Apply the processing to each row\n",
    "processed_data = [process_row(row) for row in rows]\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "df_cleaned = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_cleaned.to_excel(\"cleaned_extracted_table_remaining_corrected.xlsx\", index=False, header=False)\n",
    "\n",
    "print(\"Data extraction and splitting complete. Saved to cleaned_extracted_table_remaining_corrected.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1908\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table.xlsx\", header=None)\n",
    "\n",
    "# Skip the first two rows and extract the remaining data\n",
    "df_table_remaining = df_table.iloc[2:]\n",
    "\n",
    "# Convert the DataFrame to a single string to process all rows together\n",
    "all_text = ' '.join(df_table_remaining[0].dropna().astype(str).tolist())\n",
    "\n",
    "# Split the text by \"O \" followed by a space, but keep the delimiter in the result\n",
    "rows = re.split(r'(O )', all_text)\n",
    "rows = [''.join(pair) for pair in zip(rows[1::2], rows[2::2])]\n",
    "\n",
    "# Function to process each row, handling the required merging logic\n",
    "def process_row(row):\n",
    "    # Split the row into individual cells by spaces (ignore quotes)\n",
    "    cleaned_matches = row.split()\n",
    "\n",
    "    # Find the index of the last cell containing a dollar sign\n",
    "    dollar_idx = None\n",
    "    for idx, cell in reversed(list(enumerate(cleaned_matches))):\n",
    "        if '$' in cell:\n",
    "            dollar_idx = idx\n",
    "            break\n",
    "\n",
    "    if dollar_idx is None:\n",
    "        # No dollar sign found, return the cleaned row as is\n",
    "        return cleaned_matches\n",
    "    \n",
    "    # Combine all cells after the last $ until the last two cells\n",
    "    combined_cell = \"_\".join(cleaned_matches[dollar_idx + 1:-2])\n",
    "    \n",
    "    # Keep the last two cells as separate columns\n",
    "    last_two_cells = cleaned_matches[-2:]\n",
    "    \n",
    "    # Construct the new row\n",
    "    new_row = cleaned_matches[:dollar_idx + 1] + [combined_cell] + last_two_cells\n",
    "\n",
    "    # Handle alphanumeric and numeric data separation\n",
    "    final_row = []\n",
    "    for i, cell in enumerate(new_row):\n",
    "        # Check if cell contains alphanumeric data and next cell is two-digit numeric data\n",
    "        if re.match(r'^[A-Za-z0-9]+$', cell) and i+1 < len(new_row) and re.match(r'^\\d{2}$', new_row[i+1]):\n",
    "            # Add the current cell and the two-digit numeric cell as separate cells\n",
    "            final_row.append(cell)\n",
    "            final_row.append(new_row[i+1])\n",
    "            if i+2 < len(new_row) and '$' in new_row[i+2]:\n",
    "                # If the following cell contains a $, keep it as a separate cell\n",
    "                final_row.append(new_row[i+2])\n",
    "            else:\n",
    "                # Add a blank cell if no data exists between the alphanumeric and $ sign cell\n",
    "                final_row.append('')\n",
    "        else:\n",
    "            # Add the current cell to the final row\n",
    "            final_row.append(cell)\n",
    "\n",
    "    return final_row\n",
    "\n",
    "# Apply the processing to each row\n",
    "processed_data = [process_row(row) for row in rows]\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "df_cleaned = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_cleaned.to_excel(\"cleaned_extracted_table_remaining_corrected.xlsx\", index=False, header=False)\n",
    "\n",
    "print(\"Data extraction and splitting complete. Saved to cleaned_extracted_table_remaining_corrected.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
