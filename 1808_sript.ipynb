{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table.xlsx\", header=None)\n",
    "\n",
    "# Skip the first two rows and extract the remaining data\n",
    "df_table_remaining = df_table.iloc[2:]\n",
    "\n",
    "# Function to process each row, handling the required merging logic\n",
    "def process_row(row):\n",
    "    # Find the last occurrence of a cell with a dollar sign ($)\n",
    "    dollar_idx = None\n",
    "    for idx, cell in reversed(list(enumerate(row))):\n",
    "        if isinstance(cell, str) and '$' in cell:\n",
    "            dollar_idx = idx\n",
    "            break\n",
    "    \n",
    "    if dollar_idx is None:\n",
    "        # No dollar sign found, return the row as is\n",
    "        return row\n",
    "    \n",
    "    # Combine all cells after the last $ until the last two cells\n",
    "    combined_cell = \"_\".join(row[dollar_idx + 1:-2])\n",
    "    \n",
    "    # Keep the last two cells as separate columns\n",
    "    last_two_cells = row[-2:]\n",
    "    \n",
    "    # Construct the new row\n",
    "    new_row = list(row[:dollar_idx + 1]) + [combined_cell] + last_two_cells\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "# Apply the processing to each row\n",
    "processed_data = [process_row(row) for row in df_table_remaining.values]\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "df_cleaned = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_cleaned.to_excel(\"cleaned_extracted_table_remaining_corrected.xlsx\", index=False, header=False)\n",
    "\n",
    "print(\"Data extraction and splitting complete. Saved to cleaned_extracted_table_remaining_corrected.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######working\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = '3.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(f\"Error: Unable to load image at path {image_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sharpen the image\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    sharp = cv2.filter2D(gray, -1, kernel)\n",
    "    \n",
    "    # Denoise the image\n",
    "    denoised = cv2.fastNlMeansDenoising(sharp, h=30)\n",
    "    \n",
    "    # Resize the image\n",
    "    height, width = denoised.shape\n",
    "    resized = cv2.resize(denoised, (width * 3, height * 3))\n",
    "    \n",
    "    # Apply both adaptive and global thresholding\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(resized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY, 11, 2)\n",
    "    _, global_thresh = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Combine both thresholding results\n",
    "    combined_thresh = cv2.bitwise_or(adaptive_thresh, global_thresh)\n",
    "    \n",
    "    return combined_thresh\n",
    "\n",
    "# Preprocess the image\n",
    "thresh = preprocess_image(image)\n",
    "\n",
    "# Use Tesseract to perform OCR with custom configurations\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT, config=custom_config)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Initialize variables to store row data\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = table_data['line_num'].min()\n",
    "\n",
    "# Iterate through the table data\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        if current_row:\n",
    "            rows.append(' '.join(current_row))\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    # Concatenate text within the same line\n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(' '.join(current_row))\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_table = pd.DataFrame(rows)\n",
    "\n",
    "# Ensure DataFrame has columns and rename them if needed\n",
    "# Assuming the first row of `rows` is the header\n",
    "if not df_table.empty:\n",
    "    header = df_table.iloc[0]\n",
    "    df_table = df_table[1:]\n",
    "    df_table.columns = header\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"extracted_table.xlsx\", index=False)\n",
    "\n",
    "print(\"Data extraction complete. Saved to extracted_table.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
