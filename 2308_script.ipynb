{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "######working\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = '15.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(f\"Error: Unable to load image at path {image_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sharpen the image\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    sharp = cv2.filter2D(gray, -1, kernel)\n",
    "    \n",
    "    # Denoise the image\n",
    "    denoised = cv2.fastNlMeansDenoising(sharp, h=30)\n",
    "    \n",
    "    # Resize the image\n",
    "    height, width = denoised.shape\n",
    "    resized = cv2.resize(denoised, (width * 3, height * 3))\n",
    "    \n",
    "    # Apply both adaptive and global thresholding\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(resized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY, 11, 2)\n",
    "    _, global_thresh = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Combine both thresholding results\n",
    "    combined_thresh = cv2.bitwise_or(adaptive_thresh, global_thresh)\n",
    "    \n",
    "    return combined_thresh\n",
    "\n",
    "# Preprocess the image\n",
    "thresh = preprocess_image(image)\n",
    "\n",
    "# Use Tesseract to perform OCR with custom configurations\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT, config=custom_config)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Initialize variables to store row data\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = table_data['line_num'].min()\n",
    "\n",
    "# Iterate through the table data\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        if current_row:\n",
    "            rows.append(' '.join(current_row))\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    # Concatenate text within the same line\n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(' '.join(current_row))\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_table = pd.DataFrame(rows)\n",
    "\n",
    "# Ensure DataFrame has columns and rename them if needed\n",
    "# Assuming the first row of `rows` is the header\n",
    "if not df_table.empty:\n",
    "    header = df_table.iloc[0]\n",
    "    df_table = df_table[1:]\n",
    "    df_table.columns = header\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"extracted_table_2308.xlsx\", index=False)\n",
    "\n",
    "print(\"Data extraction complete. Saved to extracted_table.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and splitting complete. Saved to cleaned_extracted_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "###working \n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table_2308.xlsx\", header=None)\n",
    "\n",
    "# Function to clean and split lines where \"O \" is present\n",
    "def clean_and_split(line):\n",
    "    if isinstance(line, str) and line.startswith(\"O \"):\n",
    "        # Replace multiple spaces with a single space\n",
    "        line = re.sub(r'\\s+', ' ', line)\n",
    "        # Split the line by spaces\n",
    "        split_line = line.split(' ')\n",
    "        # Join the elements with semicolons\n",
    "        return ';'.join(split_line)\n",
    "    return line\n",
    "\n",
    "# Function to merge lines if a line might be a continuation of the previous line\n",
    "def merge_lines(data):\n",
    "    merged_data = []\n",
    "    for i, line in enumerate(data):\n",
    "        if i > 0:\n",
    "            # Check if the current line is a continuation of the previous line\n",
    "            if isinstance(line, str) and line.islower():\n",
    "                # Merge with the previous line\n",
    "                merged_data[-1] += \" \" + line.strip()\n",
    "            else:\n",
    "                merged_data.append(line)\n",
    "        else:\n",
    "            merged_data.append(line)\n",
    "    return merged_data\n",
    "\n",
    "# Apply the merge_lines function to combine split lines\n",
    "merged_table = merge_lines(df_table[0].tolist())\n",
    "\n",
    "# Apply the cleaning function to each row in the merged data\n",
    "df_table_cleaned = pd.Series(merged_table).apply(clean_and_split)\n",
    "\n",
    "# Split the semicolon-separated values into separate columns\n",
    "df_table_split = df_table_cleaned.str.split(';', expand=True)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_table_split.to_excel(\"cleaned_extracted_table.xlsx\", index=False)\n",
    "\n",
    "print(\"Data cleaning and splitting complete. Saved to cleaned_extracted_table.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##handles \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table.xlsx\", header=None)\n",
    "\n",
    "# Skip the first two rows and extract the remaining data\n",
    "df_table_remaining = df_table.iloc[2:]\n",
    "\n",
    "# Convert the DataFrame to a single string to process all rows together\n",
    "all_text = ' '.join(df_table_remaining[0].dropna().astype(str).tolist())\n",
    "\n",
    "# Split the text by \"O \" followed by a space, but keep the delimiter in the result\n",
    "rows = re.split(r'(O )', all_text)\n",
    "rows = [''.join(pair) for pair in zip(rows[1::2], rows[2::2])]\n",
    "\n",
    "# Function to process each row, handling the required merging and splitting logic\n",
    "def process_row(row):\n",
    "    # Split the row into individual cells\n",
    "    cleaned_matches = row.split()\n",
    "\n",
    "    # Handle missing data between alphanumeric and numeric values\n",
    "    final_row = []\n",
    "    i = 0\n",
    "    while i < len(cleaned_matches):\n",
    "        if i + 2 < len(cleaned_matches) and re.match(r'^[A-Za-z0-9]+$', cleaned_matches[i]) and re.match(r'^\\d{2}$', cleaned_matches[i + 1]) and '$' in cleaned_matches[i + 2]:\n",
    "            # Add the current cell, the two-digit numeric cell, and the $ cell as separate cells\n",
    "            final_row.append(cleaned_matches[i])\n",
    "            final_row.append(cleaned_matches[i + 1])\n",
    "            final_row.append(cleaned_matches[i + 2])\n",
    "            i += 3\n",
    "        else:\n",
    "            final_row.append(cleaned_matches[i])\n",
    "            i += 1\n",
    "\n",
    "    return final_row\n",
    "\n",
    "# Apply the processing to each row\n",
    "processed_data = [process_row(row) for row in rows]\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "df_cleaned = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_cleaned.to_excel(\"cleaned_extracted_table_remaining_corrected.xlsx\", index=False, header=False)\n",
    "\n",
    "print(\"Data extraction and splitting complete. Saved to cleaned_extracted_table_remaining_corrected.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###  updated code handing words between alphanumeric and $ with _ and segment column \n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the previously extracted data from Excel\n",
    "df_table = pd.read_excel(\"extracted_table.xlsx\", header=None)\n",
    "\n",
    "# Function to clean and split lines where \"O \" is present\n",
    "def clean_and_split(line):\n",
    "    if isinstance(line, str) and line.startswith(\"O \"):\n",
    "        # Replace multiple spaces with a single space\n",
    "        line = re.sub(r'\\s+', ' ', line)\n",
    "        # Split the line by spaces\n",
    "        split_line = line.split(' ')\n",
    "\n",
    "        # Logic 1: Add _ (underscore) between alphanumeric data and $ sign data\n",
    "        for i in range(len(split_line) - 1):\n",
    "            if re.match(r'^[A-Za-z0-9]+$', split_line[i]) and '$' in split_line[i + 1]:\n",
    "                split_line[i] += \"_\" + split_line.pop(i + 1)\n",
    "                break  # assuming only one such case per line\n",
    "\n",
    "        # Logic 2: Handle provider, 2-digit numeric, and $ sign case\n",
    "        if 'provider' in split_line:\n",
    "            provider_idx = split_line.index('provider')\n",
    "            if provider_idx + 2 < len(split_line) and re.match(r'^\\d{2}$', split_line[provider_idx + 1]) and '$' in split_line[provider_idx + 2]:\n",
    "                pass  # Leave the data as is, it fits the expected pattern\n",
    "            else:\n",
    "                # If the pattern doesn't match, insert 10 as the data after 'provider'\n",
    "                split_line.insert(provider_idx + 1, '10')\n",
    "\n",
    "        # Join the elements with semicolons\n",
    "        return ';'.join(split_line)\n",
    "    return line\n",
    "\n",
    "# Function to merge lines if a line might be a continuation of the previous line\n",
    "def merge_lines(data):\n",
    "    merged_data = []\n",
    "    for i, line in enumerate(data):\n",
    "        if i > 0:\n",
    "            # Check if the current line is a continuation of the previous line\n",
    "            if isinstance(line, str) and line.islower():\n",
    "                # Merge with the previous line\n",
    "                merged_data[-1] += \" \" + line.strip()\n",
    "            else:\n",
    "                merged_data.append(line)\n",
    "        else:\n",
    "            merged_data.append(line)\n",
    "    return merged_data\n",
    "\n",
    "# Apply the merge_lines function to combine split lines\n",
    "merged_table = merge_lines(df_table[0].tolist())\n",
    "\n",
    "# Apply the cleaning function to each row in the merged data\n",
    "df_table_cleaned = pd.Series(merged_table).apply(clean_and_split)\n",
    "\n",
    "# Split the semicolon-separated values into separate columns\n",
    "df_table_split = df_table_cleaned.str.split(';', expand=True)\n",
    "\n",
    "# Save the cleaned and split data to a new Excel file\n",
    "df_table_split.to_excel(\"cleaned_extracted_table.xlsx\", index=False)\n",
    "\n",
    "print(\"Data cleaning and splitting complete. Saved to cleaned_extracted_table.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
