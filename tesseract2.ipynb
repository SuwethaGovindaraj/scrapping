{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('scrap_image.png')\n",
    "\n",
    "# Preprocess the image (convert to grayscale, apply thresholding, etc.)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Use Tesseract to do OCR on the preprocessed image\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Print the table data\n",
    "table_data.to_excel(\"sample.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [['Bootstrap', 'Ed', 'First', 'Larry', 'Last', 'Otto', 'Thornton', 'the', 'Handle', '@mdo', '@fat', '@twitter', 'Responsive', 'Bird', 'Table', '(Striped)'], ['Mark'], ['Jacob']]\n",
      "Max columns: 16\n"
     ]
    }
   ],
   "source": [
    "##working\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('scrap_image.png')\n",
    "\n",
    "# Preprocess the image (convert to grayscale, apply thresholding, etc.)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Use Tesseract to do OCR on the preprocessed image\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Group by line_num and sort by word_num within each line\n",
    "table_data = table_data.sort_values(by=['line_num', 'word_num'])\n",
    "\n",
    "# Create a list to store rows of text\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = 1\n",
    "\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        rows.append(current_row)\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(current_row)\n",
    "\n",
    "# Print the rows to check the structure\n",
    "print(\"Rows:\", rows)\n",
    "\n",
    "# Determine the maximum number of columns\n",
    "max_columns = max(len(row) for row in rows)\n",
    "print(\"Max columns:\", max_columns)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "# Adjust the number of columns based on max_columns\n",
    "df_table = pd.DataFrame(rows)\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"sample.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [['Bootstrap', 'Ed', 'First', 'Larry', 'Last', 'Otto', 'Thornton', 'the', 'Handle', '@mdo', '@fat', '@twitter', 'Responsive', 'Bird', 'Table', '(Striped)'], ['Mark'], ['Jacob']]\n",
      "Max columns: 16\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('scrap_image.png')\n",
    "\n",
    "# Preprocess the image (convert to grayscale, apply thresholding, etc.)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Use Tesseract to do OCR on the preprocessed image\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Group by line_num and sort by word_num within each line\n",
    "table_data = table_data.sort_values(by=['line_num', 'word_num'])\n",
    "\n",
    "# Create a list to store rows of text\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = 1\n",
    "\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        # Add the row to rows only if it's not empty\n",
    "        if current_row:\n",
    "            rows.append(current_row)\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(current_row)\n",
    "\n",
    "# Print the rows to check the structure\n",
    "print(\"Rows:\", rows)\n",
    "\n",
    "# Determine the maximum number of columns and remove empty columns\n",
    "max_columns = max(len(row) for row in rows)\n",
    "print(\"Max columns:\", max_columns)\n",
    "\n",
    "# Create a DataFrame from the list of rows, removing empty columns\n",
    "df_table = pd.DataFrame(rows)\n",
    "df_table = df_table.loc[:, ~df_table.columns.isnull()]\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"sample.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to sample.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('1.jpeg')\n",
    "\n",
    "# Preprocess the image (convert to grayscale, apply thresholding, etc.)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Use Tesseract to do OCR on the preprocessed image\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT)\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Extract header from the first row\n",
    "header = table_data[table_data['line_num'] == table_data['line_num'].min()]['text'].values\n",
    "\n",
    "# Group by line_num and sort by word_num within each line\n",
    "table_data = table_data.sort_values(by=['line_num', 'word_num'])\n",
    "\n",
    "# Create a list to store rows of text\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = table_data['line_num'].min()\n",
    "\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        # Add the row to rows only if it's not empty\n",
    "        if current_row:\n",
    "            rows.append(current_row)\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(current_row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_table = pd.DataFrame(rows)\n",
    "\n",
    "# Ensure all rows have the same number of columns as the header\n",
    "max_columns = len(header)\n",
    "df_table = df_table.reindex(columns=range(max_columns), fill_value='')\n",
    "\n",
    "# Rename columns with header\n",
    "df_table.columns = header\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"sample_2.xlsx\", index=False)\n",
    "\n",
    "print(\"Data extraction complete. Saved to sample.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in c:\\users\\suwetha\\appdata\\roaming\\python\\python39\\site-packages (0.3.10)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (9.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\suwetha\\appdata\\roaming\\python\\python39\\site-packages (from opencv-python) (1.21.6)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract\n",
    "!pip install pillow\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "C:\\Users\\SUWETHA\\AppData\\Roaming\\Python\\Python39\\site-packages\\easyocr\\detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "C:\\Users\\SUWETHA\\AppData\\Roaming\\Python\\Python39\\site-packages\\easyocr\\recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text  \\\n",
      "0                              Upcoming   \n",
      "1                               Stinbol   \n",
      "2                               Coripan   \n",
      "3                                  KAMl   \n",
      "4                             Exchlanol   \n",
      "..                                  ...   \n",
      "81                                   Ee   \n",
      "82                            3,326,515   \n",
      "83                           02/17/3021   \n",
      "84                          41678015400   \n",
      "85  Lini ufolrLd O217iozt\" -Se [cGaRro&   \n",
      "\n",
      "                                                bbox  \n",
      "0             [[17, 3], [94, 3], [94, 28], [17, 28]]  \n",
      "1           [[20, 46], [52, 46], [52, 54], [20, 54]]  \n",
      "2         [[80, 46], [116, 46], [116, 54], [80, 54]]  \n",
      "3       [[120, 48], [144, 48], [144, 54], [120, 54]]  \n",
      "4       [[210, 46], [248, 46], [248, 54], [210, 54]]  \n",
      "..                                               ...  \n",
      "81  [[308, 244], [330, 244], [330, 250], [308, 250]]  \n",
      "82  [[381, 241], [421, 241], [421, 253], [381, 253]]  \n",
      "83  [[455, 241], [503, 241], [503, 253], [455, 253]]  \n",
      "84  [[568, 242], [628, 242], [628, 250], [568, 250]]  \n",
      "85  [[492, 264], [658, 264], [658, 272], [492, 272]]  \n",
      "\n",
      "[86 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the reader with the desired languages\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Read the text from the image\n",
    "results = reader.readtext('image.png')\n",
    "\n",
    "# Convert the results to a structured format\n",
    "table_data = []\n",
    "for result in results:\n",
    "    text = result[1]\n",
    "    bbox = result[0]\n",
    "    table_data.append({'text': text, 'bbox': bbox})\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(table_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Upcoming</td>\n",
       "      <td>[[17, 3], [94, 3], [94, 28], [17, 28]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stinbol</td>\n",
       "      <td>[[20, 46], [52, 46], [52, 54], [20, 54]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coripan</td>\n",
       "      <td>[[80, 46], [116, 46], [116, 54], [80, 54]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KAMl</td>\n",
       "      <td>[[120, 48], [144, 48], [144, 54], [120, 54]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exchlanol</td>\n",
       "      <td>[[210, 46], [248, 46], [248, 54], [210, 54]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Ee</td>\n",
       "      <td>[[308, 244], [330, 244], [330, 250], [308, 250]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3,326,515</td>\n",
       "      <td>[[381, 241], [421, 241], [421, 253], [381, 253]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>02/17/3021</td>\n",
       "      <td>[[455, 241], [503, 241], [503, 253], [455, 253]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>41678015400</td>\n",
       "      <td>[[568, 242], [628, 242], [628, 250], [568, 250]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Lini ufolrLd O217iozt\" -Se [cGaRro&amp;</td>\n",
       "      <td>[[492, 264], [658, 264], [658, 272], [492, 272]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text  \\\n",
       "0                              Upcoming   \n",
       "1                               Stinbol   \n",
       "2                               Coripan   \n",
       "3                                  KAMl   \n",
       "4                             Exchlanol   \n",
       "..                                  ...   \n",
       "81                                   Ee   \n",
       "82                            3,326,515   \n",
       "83                           02/17/3021   \n",
       "84                          41678015400   \n",
       "85  Lini ufolrLd O217iozt\" -Se [cGaRro&   \n",
       "\n",
       "                                                bbox  \n",
       "0             [[17, 3], [94, 3], [94, 28], [17, 28]]  \n",
       "1           [[20, 46], [52, 46], [52, 54], [20, 54]]  \n",
       "2         [[80, 46], [116, 46], [116, 54], [80, 54]]  \n",
       "3       [[120, 48], [144, 48], [144, 54], [120, 54]]  \n",
       "4       [[210, 46], [248, 46], [248, 54], [210, 54]]  \n",
       "..                                               ...  \n",
       "81  [[308, 244], [330, 244], [330, 250], [308, 250]]  \n",
       "82  [[381, 241], [421, 241], [421, 253], [381, 253]]  \n",
       "83  [[455, 241], [503, 241], [503, 253], [455, 253]]  \n",
       "84  [[568, 242], [628, 242], [628, 250], [568, 250]]  \n",
       "85  [[492, 264], [658, 264], [658, 272], [492, 272]]  \n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "###working\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('scrap1.jpg')\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    return thresh\n",
    "\n",
    "# Preprocess the image\n",
    "thresh = preprocess_image(image)\n",
    "\n",
    "# Use Tesseract to perform OCR\n",
    "data = pytesseract.image_to_data(thresh, output_type=Output.DICT, config='--psm 6')\n",
    "\n",
    "# Extract the OCR results into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out non-table data\n",
    "table_data = df[df['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Initialize variables to store row data\n",
    "rows = []\n",
    "current_row = []\n",
    "current_line_num = table_data['line_num'].min()\n",
    "\n",
    "# Iterate through the table data\n",
    "for i, row in table_data.iterrows():\n",
    "    if row['line_num'] != current_line_num:\n",
    "        if current_row:\n",
    "            rows.append(' '.join(current_row))\n",
    "        current_row = []\n",
    "        current_line_num = row['line_num']\n",
    "    \n",
    "    # Concatenate text within the same line\n",
    "    current_row.append(row['text'])\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    rows.append(' '.join(current_row))\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_table = pd.DataFrame(rows)\n",
    "\n",
    "# Ensure DataFrame has columns and rename them if needed\n",
    "# Assuming the first row of `rows` is the header\n",
    "header = df_table.iloc[0]\n",
    "df_table = df_table[1:]\n",
    "df_table.columns = header\n",
    "\n",
    "# Save to Excel\n",
    "df_table.to_excel(\"extracted_table.xlsx\", index=False)\n",
    "\n",
    "print(\"Data extraction complete. Saved to extracted_table.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction and appending complete. Saved to extracted_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "## append data in same excel\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    return thresh\n",
    "\n",
    "# Function to extract data from image\n",
    "def extract_data_from_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    thresh = preprocess_image(image)\n",
    "    \n",
    "    # Perform OCR\n",
    "    data = pytesseract.image_to_data(thresh, output_type=Output.DICT, config='--psm 6')\n",
    "    \n",
    "    # Extract the OCR results into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Filter out non-table data\n",
    "    table_data = df[df['text'].str.strip().astype(bool)]\n",
    "    \n",
    "    # Initialize variables to store row data\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    current_line_num = table_data['line_num'].min()\n",
    "    \n",
    "    # Iterate through the table data\n",
    "    for i, row in table_data.iterrows():\n",
    "        if row['line_num'] != current_line_num:\n",
    "            if current_row:\n",
    "                rows.append(' '.join(current_row))\n",
    "            current_row = []\n",
    "            current_line_num = row['line_num']\n",
    "        \n",
    "        # Concatenate text within the same line\n",
    "        current_row.append(row['text'])\n",
    "    \n",
    "    # Append the last row\n",
    "    if current_row:\n",
    "        rows.append(' '.join(current_row))\n",
    "    \n",
    "    # Create a DataFrame from the list of rows\n",
    "    df_table = pd.DataFrame(rows)\n",
    "    \n",
    "    # Ensure DataFrame has columns and rename them if needed\n",
    "    # Assuming the first row of `rows` is the header\n",
    "    header = df_table.iloc[0]\n",
    "    df_table = df_table[1:]\n",
    "    df_table.columns = header\n",
    "    \n",
    "    return df_table\n",
    "\n",
    "# Path to the existing Excel file\n",
    "excel_file_path = 'extracted_table.xlsx'\n",
    "\n",
    "# Extract data from the first image and save to Excel\n",
    "df_existing = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Extract data from the new image\n",
    "new_image_path = 'scrap1.jpg'\n",
    "df_new = extract_data_from_image(new_image_path)\n",
    "\n",
    "# Append new data to the existing DataFrame\n",
    "df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to Excel\n",
    "df_combined.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(\"Data extraction and appending complete. Saved to extracted_table.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "2 columns passed, passed data had 14 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m   1031\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 2 columns passed, passed data had 14 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16660\\591456833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[0mnew_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mail.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mupdate_excel_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_image_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcel_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16660\\591456833.py\u001b[0m in \u001b[0;36mupdate_excel_file\u001b[1;34m(new_image_path, excel_file_path)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m# Extract data from the new image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_data_from_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Ensure the new data matches the structure of the existing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16660\\591456833.py\u001b[0m in \u001b[0;36mextract_data_from_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mdf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    719\u001b[0m                         \u001b[1;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[0;32m    722\u001b[0m                         \u001b[1;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                         \u001b[1;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m     \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 2 columns passed, passed data had 14 columns"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    # Dilate to fill gaps in lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    return dilated\n",
    "\n",
    "# Function to extract data from image\n",
    "def extract_data_from_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_image(image)\n",
    "    \n",
    "    # Perform OCR\n",
    "    custom_config = r'--oem 3 --psm 6'  # LSTM OCR engine with fully automatic page segmentation\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Extract the OCR results into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Filter out non-table data\n",
    "    df = df[df['text'].str.strip().astype(bool)]\n",
    "    \n",
    "    # Group by line number and concatenate text within the same line\n",
    "    df_grouped = df.groupby('line_num')['text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "    \n",
    "    # Extract header and data separately\n",
    "    header = df_grouped.iloc[0]['text'].split()\n",
    "    data_rows = df_grouped.iloc[1:]\n",
    "    \n",
    "    # Convert data rows to a DataFrame\n",
    "    data_list = [row['text'].split() for _, row in data_rows.iterrows()]\n",
    "    \n",
    "    # Ensure all rows have the same number of columns as the header\n",
    "    max_len = len(header)\n",
    "    data_list = [row + [''] * (max_len - len(row)) for row in data_list]\n",
    "    \n",
    "    df_data = pd.DataFrame(data_list, columns=header)\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "# Path to the existing Excel file\n",
    "excel_file_path = 'extracted_table.xlsx'\n",
    "\n",
    "# Function to update the Excel file with new data\n",
    "def update_excel_file(new_image_path, excel_file_path):\n",
    "    # Extract data from the existing Excel file if it exists, otherwise create an empty DataFrame\n",
    "    try:\n",
    "        df_existing = pd.read_excel(excel_file_path)\n",
    "    except FileNotFoundError:\n",
    "        df_existing = pd.DataFrame()\n",
    "\n",
    "    # Extract data from the new image\n",
    "    df_new = extract_data_from_image(new_image_path)\n",
    "\n",
    "    # Ensure the new data matches the structure of the existing data\n",
    "    if not df_existing.empty and df_existing.columns.tolist() != df_new.columns.tolist():\n",
    "        raise ValueError(\"The columns in the new data do not match the existing data columns.\")\n",
    "\n",
    "    # Append new data to the existing DataFrame\n",
    "    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to Excel\n",
    "    df_combined.to_excel(excel_file_path, index=False)\n",
    "\n",
    "    print(f\"Data extraction and appending complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'mail.jpeg'\n",
    "update_excel_file(new_image_path, excel_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "2 columns passed, passed data had 14 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m   1031\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 2 columns passed, passed data had 14 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16660\\2868960847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Extract data and save to Excel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mdf_extracted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_data_from_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[0msave_to_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_extracted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_excel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16660\\2868960847.py\u001b[0m in \u001b[0;36mextract_data_from_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mdf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    719\u001b[0m                         \u001b[1;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[0;32m    722\u001b[0m                         \u001b[1;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                         \u001b[1;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m     \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 2 columns passed, passed data had 14 columns"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    return dilated\n",
    "\n",
    "# Function to extract data from the image\n",
    "def extract_data_from_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Filter out rows without text\n",
    "    df = df[df['text'].str.strip().astype(bool)]\n",
    "    \n",
    "    # Group by line number and concatenate text\n",
    "    df_grouped = df.groupby('line_num')['text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "    \n",
    "    # Check if header exists and extract it\n",
    "    if df_grouped.empty:\n",
    "        raise ValueError(\"No text found in image.\")\n",
    "    \n",
    "    header = df_grouped.iloc[0]['text'].split()\n",
    "    data_rows = df_grouped.iloc[1:]\n",
    "    \n",
    "    # Ensure all rows have the same number of columns as the header\n",
    "    data_list = [row['text'].split() for _, row in data_rows.iterrows()]\n",
    "    max_len = len(header)\n",
    "    for row in data_list:\n",
    "        if len(row) < max_len:\n",
    "            row.extend([''] * (max_len - len(row)))\n",
    "    \n",
    "    df_data = pd.DataFrame(data_list, columns=header)\n",
    "    return df_data\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'mail.jpeg'\n",
    "output_excel_path = 'extracted_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_data_from_image(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    return dilated\n",
    "\n",
    "# Function to extract data from the image\n",
    "def extract_data_from_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Collect text data from each block and line\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append(data['text'][i])\n",
    "    \n",
    "    # Combine text blocks into a single DataFrame\n",
    "    df = pd.DataFrame(text_blocks, columns=['Text'])\n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = '1.png'\n",
    "output_excel_path = 'extracted_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_data_from_image(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    return dilated\n",
    "\n",
    "# Function to extract tabular data from the image\n",
    "def extract_tabular_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract data using pytesseract\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Initialize lists to store text blocks and their positions\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append({\n",
    "                'text': data['text'][i],\n",
    "                'left': data['left'][i],\n",
    "                'top': data['top'][i],\n",
    "                'width': data['width'][i],\n",
    "                'height': data['height'][i]\n",
    "            })\n",
    "    \n",
    "    # Sort text blocks by their vertical position and then by horizontal position\n",
    "    text_blocks = sorted(text_blocks, key=lambda x: (x['top'], x['left']))\n",
    "    \n",
    "    # Extract columns and rows based on sorted blocks\n",
    "    columns = []\n",
    "    current_row = []\n",
    "    last_top = None\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        if last_top is not None and abs(block['top'] - last_top) > 10:\n",
    "            columns.append(current_row)\n",
    "            current_row = []\n",
    "        current_row.append(block['text'])\n",
    "        last_top = block['top']\n",
    "    \n",
    "    if current_row:\n",
    "        columns.append(current_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(columns)\n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'image.png'\n",
    "output_excel_path = 'extracted_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_tabular_data(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding for better contrast\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Apply dilation and erosion to close gaps in text\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "    return eroded\n",
    "\n",
    "# Function to extract tabular data from the image\n",
    "def extract_tabular_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract data using pytesseract\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Initialize lists to store text blocks and their positions\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append({\n",
    "                'text': data['text'][i],\n",
    "                'left': data['left'][i],\n",
    "                'top': data['top'][i],\n",
    "                'width': data['width'][i],\n",
    "                'height': data['height'][i]\n",
    "            })\n",
    "    \n",
    "    # Sort text blocks by their vertical position and then by horizontal position\n",
    "    text_blocks = sorted(text_blocks, key=lambda x: (x['top'], x['left']))\n",
    "    \n",
    "    # Extract columns and rows based on sorted blocks\n",
    "    columns = []\n",
    "    current_row = []\n",
    "    last_top = None\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        if last_top is not None and abs(block['top'] - last_top) > 10:\n",
    "            columns.append(current_row)\n",
    "            current_row = []\n",
    "        current_row.append(block['text'])\n",
    "        last_top = block['top']\n",
    "    \n",
    "    if current_row:\n",
    "        columns.append(current_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    # Find the maximum number of columns to create a uniform DataFrame\n",
    "    max_columns = max(len(row) for row in columns)\n",
    "    for i in range(len(columns)):\n",
    "        if len(columns[i]) < max_columns:\n",
    "            columns[i].extend([''] * (max_columns - len(columns[i])))\n",
    "    \n",
    "    df = pd.DataFrame(columns)\n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'scrap_image.png'\n",
    "output_excel_path = 'extracted_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_tabular_data(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "##as per our table \n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding for better contrast\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Apply morphological transformations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "    return eroded\n",
    "\n",
    "# Function to extract tabular data from the image\n",
    "def extract_tabular_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract data using pytesseract\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Initialize lists to store text blocks and their positions\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append({\n",
    "                'text': data['text'][i],\n",
    "                'left': data['left'][i],\n",
    "                'top': data['top'][i],\n",
    "                'width': data['width'][i],\n",
    "                'height': data['height'][i]\n",
    "            })\n",
    "    \n",
    "    # Sort text blocks by their vertical position and then by horizontal position\n",
    "    text_blocks = sorted(text_blocks, key=lambda x: (x['top'], x['left']))\n",
    "    \n",
    "    # Extract columns and rows based on sorted blocks\n",
    "    columns = []\n",
    "    current_row = []\n",
    "    last_top = None\n",
    "    last_left = None\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        if last_top is not None and abs(block['top'] - last_top) > 10:\n",
    "            columns.append(current_row)\n",
    "            current_row = []\n",
    "        \n",
    "        # Check if the text block belongs to the same column\n",
    "        if last_left is not None and abs(block['left'] - last_left) > 10:\n",
    "            current_row.append('')  # Empty cell for alignment\n",
    "        \n",
    "        current_row.append(block['text'])\n",
    "        last_top = block['top']\n",
    "        last_left = block['left']\n",
    "    \n",
    "    if current_row:\n",
    "        columns.append(current_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    # Find the maximum number of columns to create a uniform DataFrame\n",
    "    max_columns = max(len(row) for row in columns)\n",
    "    for i in range(len(columns)):\n",
    "        if len(columns[i]) < max_columns:\n",
    "            columns[i].extend([''] * (max_columns - len(columns[i])))\n",
    "    \n",
    "    df = pd.DataFrame(columns)\n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'scrap1.jpg'\n",
    "output_excel_path = 'extracted_table_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_tabular_data(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding for better contrast\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Apply morphological transformations to enhance table structure\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "    return eroded\n",
    "\n",
    "# Function to extract tabular data from the image\n",
    "def extract_tabular_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract data using pytesseract\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Initialize lists to store text blocks and their positions\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append({\n",
    "                'text': data['text'][i],\n",
    "                'left': data['left'][i],\n",
    "                'top': data['top'][i],\n",
    "                'width': data['width'][i],\n",
    "                'height': data['height'][i]\n",
    "            })\n",
    "    \n",
    "    # Group text blocks by rows based on their vertical position\n",
    "    rows = {}\n",
    "    for block in text_blocks:\n",
    "        top = block['top']\n",
    "        if top not in rows:\n",
    "            rows[top] = []\n",
    "        rows[top].append(block)\n",
    "    \n",
    "    # Sort rows by vertical position\n",
    "    sorted_rows = sorted(rows.items(), key=lambda x: x[0])\n",
    "    \n",
    "    # Extract columns for each row\n",
    "    table_data = []\n",
    "    for _, blocks in sorted_rows:\n",
    "        blocks = sorted(blocks, key=lambda x: x['left'])\n",
    "        row_data = [block['text'] for block in blocks]\n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    # Find the maximum number of columns to create a uniform DataFrame\n",
    "    max_columns = max(len(row) for row in table_data)\n",
    "    for i in range(len(table_data)):\n",
    "        if len(table_data[i]) < max_columns:\n",
    "            table_data[i].extend([''] * (max_columns - len(table_data[i])))\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Adjust header row if needed\n",
    "    if len(df) > 0:\n",
    "        header = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = header\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'scrap1.jpg'\n",
    "output_excel_path = 'extracted_table_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_tabular_data(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Use adaptive thresholding for better contrast\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Apply morphological transformations to enhance table structure\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "    # Optional: Apply additional techniques to enhance lines and text\n",
    "    edges = cv2.Canny(eroded, 50, 150)\n",
    "    combined = cv2.addWeighted(eroded, 0.8, edges, 0.2, 0)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Function to extract tabular data from the image\n",
    "def extract_tabular_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract data using pytesseract\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Initialize lists to store text blocks and their positions\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append({\n",
    "                'text': data['text'][i],\n",
    "                'left': data['left'][i],\n",
    "                'top': data['top'][i],\n",
    "                'width': data['width'][i],\n",
    "                'height': data['height'][i]\n",
    "            })\n",
    "    \n",
    "    # Group text blocks by rows based on their vertical position\n",
    "    rows = {}\n",
    "    for block in text_blocks:\n",
    "        top = block['top']\n",
    "        if top not in rows:\n",
    "            rows[top] = []\n",
    "        rows[top].append(block)\n",
    "    \n",
    "    # Sort rows by vertical position\n",
    "    sorted_rows = sorted(rows.items(), key=lambda x: x[0])\n",
    "    \n",
    "    # Extract columns for each row\n",
    "    table_data = []\n",
    "    for _, blocks in sorted_rows:\n",
    "        blocks = sorted(blocks, key=lambda x: x['left'])\n",
    "        row_data = [block['text'] for block in blocks]\n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    # Find the maximum number of columns to create a uniform DataFrame\n",
    "    max_columns = max(len(row) for row in table_data)\n",
    "    for i in range(len(table_data)):\n",
    "        if len(table_data[i]) < max_columns:\n",
    "            table_data[i].extend([''] * (max_columns - len(table_data[i])))\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Adjust header row if needed\n",
    "    if len(df) > 0:\n",
    "        header = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = header\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'scrap1.jpg'\n",
    "output_excel_path = 'extracted_table_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_tabular_data(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to extracted_table_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the image for better OCR results\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Use adaptive thresholding to handle varying lighting conditions\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Apply dilation to enhance the structure of the text\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    \n",
    "    # Optional: Apply erosion to remove small noise\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "    return eroded\n",
    "\n",
    "# Function to extract tabular data from the image\n",
    "def extract_tabular_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract data using pytesseract\n",
    "    data = pytesseract.image_to_data(processed_image, output_type=Output.DICT, config=custom_config)\n",
    "    \n",
    "    # Initialize lists to store text blocks and their positions\n",
    "    text_blocks = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():\n",
    "            text_blocks.append({\n",
    "                'text': data['text'][i],\n",
    "                'left': data['left'][i],\n",
    "                'top': data['top'][i],\n",
    "                'width': data['width'][i],\n",
    "                'height': data['height'][i]\n",
    "            })\n",
    "    \n",
    "    # Group text blocks by rows based on their vertical position\n",
    "    rows = {}\n",
    "    for block in text_blocks:\n",
    "        top = block['top']\n",
    "        if top not in rows:\n",
    "            rows[top] = []\n",
    "        rows[top].append(block)\n",
    "    \n",
    "    # Sort rows by vertical position\n",
    "    sorted_rows = sorted(rows.items(), key=lambda x: x[0])\n",
    "    \n",
    "    # Extract columns for each row\n",
    "    table_data = []\n",
    "    for _, blocks in sorted_rows:\n",
    "        blocks = sorted(blocks, key=lambda x: x['left'])\n",
    "        row_data = [block['text'] for block in blocks]\n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    # Find the maximum number of columns to create a uniform DataFrame\n",
    "    max_columns = max(len(row) for row in table_data)\n",
    "    for i in range(len(table_data)):\n",
    "        if len(table_data[i]) < max_columns:\n",
    "            table_data[i].extend([''] * (max_columns - len(table_data[i])))\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Adjust header row if needed\n",
    "    if len(df) > 0:\n",
    "        header = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = header\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to save the extracted data to an Excel file\n",
    "def save_to_excel(df, excel_file_path):\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data extraction complete. Saved to {excel_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "new_image_path = 'scrap1.jpg'\n",
    "output_excel_path = 'extracted_table_data.xlsx'\n",
    "\n",
    "# Extract data and save to Excel\n",
    "df_extracted = extract_tabular_data(new_image_path)\n",
    "save_to_excel(df_extracted, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
